{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Instalar Librerias y definición de datos.**"
      ],
      "metadata": {
        "id": "dgerx-okH8gj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install scikit-surprise\n",
        "#!pip install lightfm\n",
        "\n",
        "###############################################################################\n",
        "# pemalink: https://github.com/JossueGG/tec_bigdata_equipo17/blob/30ae4d31c8f6bf2b6be5bf47f2294a16199b19c4/ratings_small.csv\n",
        "\n",
        "# URL del archivo CSV en git o un contenedor\n",
        "url = 'https://raw.githubusercontent.com/JossueGG/tec_bigdata_equipo17/30ae4d31c8f6bf2b6be5bf47f2294a16199b19c4/ratings_small.csv?token=GHSAT0AAAAAACSA6SWKKTOK5AYQCXS4PTAAZSOELKQ'\n"
      ],
      "metadata": {
        "id": "HNktJJ__B1bY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Entrega 1***"
      ],
      "metadata": {
        "id": "tMz0vSGZBnkI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlJ2MCRlijH4",
        "outputId": "d1c13f8f-760c-4d37-ce1c-0088109a084b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top recomendaciones para el usuario: 1\n",
            "1. The Shawshank Redemption (ID: 318)\n",
            "2. All About Eve (ID: 926)\n",
            "3. Raging Bull (ID: 1228)\n",
            "4. Stand by Me (ID: 1259)\n",
            "5. Modern Times (ID: 3462)\n",
            "\n",
            "\n",
            "\n",
            "Evaluación del modelo:\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8935  0.8979  0.8943  0.9013  0.8937  0.8961  0.0030  \n",
            "MAE (testset)     0.6893  0.6919  0.6878  0.6953  0.6857  0.6900  0.0033  \n",
            "Fit time          1.46    1.99    1.65    1.52    1.49    1.62    0.20    \n",
            "Test time         0.24    0.20    0.22    0.24    0.11    0.20    0.05    \n"
          ]
        }
      ],
      "source": [
        "#!pip install scikit-surprise\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate\n",
        "\n",
        "# Rango de las calificaciones\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Número de recomendaciones a desplegar\n",
        "rec = 5\n",
        "\n",
        "###############################################################################\n",
        "\n",
        "# Cargar los datos desde la URL\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Crear un Dataset de Surprise\n",
        "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Entrenando el modelo\n",
        "trainset = data.build_full_trainset()\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "\n",
        "# Obtener el nombre de la película a partir de su ID\n",
        "movie_titles = df[['movieId', 'title']].drop_duplicates().set_index('movieId')['title'].to_dict()\n",
        "\n",
        "# Función para obtener las mejores recomendaciones para un usuario dado\n",
        "def get_top_recommendations(user_id, n=rec):\n",
        "    items = []\n",
        "    # Obtener todos los ítems que el usuario no ha calificado\n",
        "    items_not_rated_by_user = [item for item in range(1, trainset.n_items + 1)\n",
        "                               if item not in trainset.ur[user_id]]\n",
        "    # Obtener la predicción de calificación para cada ítem no calificado\n",
        "    for item_id in items_not_rated_by_user:\n",
        "        predicted_rating = model.predict(user_id, item_id).est\n",
        "        items.append((item_id, predicted_rating))\n",
        "    # Ordenar las predicciones y devolver las mejores n recomendaciones\n",
        "    top_items = sorted(items, key=lambda x: x[1], reverse=True)[:n]\n",
        "    return [(item[0], movie_titles[item[0]]) for item in top_items]\n",
        "\n",
        "\n",
        "###############################################################################\n",
        "# Ejemplo de uso, recomendación para el usuario dado\n",
        "###############################################################################\n",
        "user_id = 1\n",
        "top_recommendations = get_top_recommendations(user_id)\n",
        "print(\"Top recomendaciones para el usuario:\", user_id)\n",
        "for rank, (movie_id, title) in enumerate(top_recommendations, 1):\n",
        "    print(f\"{rank}. {title} (ID: {movie_id})\")\n",
        "\n",
        "# Evaluar el modelo con 5-fold cross-validation\n",
        "print(\"\\n\\n\\nEvaluación del modelo:\")\n",
        "results = cross_validate(model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrega 2**"
      ],
      "metadata": {
        "id": "s65K1gQVBwhG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate, GridSearchCV\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Rango de las calificaciones\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Número de recomendaciones a desplegar\n",
        "rec = 5\n",
        "\n",
        "# Cargar los datos desde la URL\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Crear un Dataset de Surprise\n",
        "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Búsqueda de hiperparámetros para SVD\n",
        "param_grid = {\n",
        "    'n_factors': [20, 50, 100, 150],\n",
        "    'n_epochs': [10, 20, 30, 40, 50],\n",
        "    'lr_all': [0.002, 0.005, 0.01, 0.02],\n",
        "    'reg_all': [0.02, 0.05, 0.1]\n",
        "}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "# Mejor modelo SVD\n",
        "best_model = gs.best_estimator['rmse']\n",
        "best_model.fit(data.build_full_trainset())\n",
        "\n",
        "# Obtener el nombre de la película a partir de su ID\n",
        "movie_titles = df[['movieId', 'title']].drop_duplicates().set_index('movieId')['title'].to_dict()\n",
        "\n",
        "# Crear una matriz de interacciones para LightFM\n",
        "user_ids = df['userId'].astype('category').cat.codes\n",
        "item_ids = df['movieId'].astype('category').cat.codes\n",
        "interactions = coo_matrix((df['rating'], (user_ids, item_ids)))\n",
        "\n",
        "# Ajustar hiperparámetros para LightFM\n",
        "lightfm_model = LightFM(loss='warp', no_components=150, learning_rate=0.05, item_alpha=1e-6, user_alpha=1e-6)\n",
        "lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
        "\n",
        "# Función para obtener las mejores recomendaciones para un usuario dado utilizando SVD\n",
        "def get_top_recommendations_svd(user_id, n=rec):\n",
        "    items = []\n",
        "    trainset = data.build_full_trainset()\n",
        "    items_not_rated_by_user = [item for item in range(1, trainset.n_items + 1) if item not in trainset.ur[user_id]]\n",
        "    for item_id in items_not_rated_by_user:\n",
        "        predicted_rating = best_model.predict(user_id, item_id).est\n",
        "        items.append((item_id, predicted_rating))\n",
        "    top_items = sorted(items, key=lambda x: x[1], reverse=True)[:n]\n",
        "    return [(item[0], movie_titles.get(item[0], \"Título no disponible\")) for item in top_items]\n",
        "\n",
        "# Función para obtener las mejores recomendaciones para un usuario dado utilizando LightFM\n",
        "def get_top_recommendations_lightfm(user_id, n=rec):\n",
        "    user_code = df['userId'].astype('category').cat.categories.get_loc(user_id)\n",
        "    scores = lightfm_model.predict(user_code, np.arange(len(movie_titles)))\n",
        "    top_items = np.argsort(-scores)[:n]\n",
        "    return [(df['movieId'].astype('category').cat.categories[item], movie_titles.get(df['movieId'].astype('category').cat.categories[item], \"Título no disponible\")) for item in top_items]\n",
        "\n",
        "# Ejemplo de uso, recomendación para el usuario dado\n",
        "user_id = 1\n",
        "top_recommendations_svd = get_top_recommendations_svd(user_id)\n",
        "top_recommendations_lightfm = get_top_recommendations_lightfm(user_id)\n",
        "\n",
        "print(\"Top recomendaciones para el usuario usando SVD:\", user_id)\n",
        "for rank, (movie_id, title) in enumerate(top_recommendations_svd, 1):\n",
        "    print(f\"{rank}. {title} (ID: {movie_id})\")\n",
        "\n",
        "print(\"\\nTop recomendaciones para el usuario usando LightFM:\", user_id)\n",
        "for rank, (movie_id, title) in enumerate(top_recommendations_lightfm, 1):\n",
        "    print(f\"{rank}. {title} (ID: {movie_id})\")\n",
        "\n",
        "# Evaluar el modelo SVD con 5-fold cross-validation\n",
        "print(\"\\n\\n\\nEvaluación del modelo SVD:\")\n",
        "results_svd = cross_validate(best_model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Evaluar el modelo LightFM\n",
        "precision = precision_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "recall = recall_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "print(\"\\nEvaluación del modelo LightFM:\")\n",
        "print(f\"Precision at {rec}: {precision}\")\n",
        "print(f\"Recall at {rec}: {recall}\")\n",
        "\n",
        "# Ajuste de hiperparámetros LightFM\n",
        "param_grid_lightfm = {\n",
        "    'no_components': [20, 50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'item_alpha': [1e-6, 1e-5, 1e-4],\n",
        "    'user_alpha': [1e-6, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# Buscar los mejores hiperparámetros para LightFM\n",
        "best_precision = 0\n",
        "best_params = None\n",
        "for no_components in param_grid_lightfm['no_components']:\n",
        "    for learning_rate in param_grid_lightfm['learning_rate']:\n",
        "        for item_alpha in param_grid_lightfm['item_alpha']:\n",
        "            for user_alpha in param_grid_lightfm['user_alpha']:\n",
        "                lightfm_model = LightFM(loss='warp', no_components=no_components, learning_rate=learning_rate, item_alpha=item_alpha, user_alpha=user_alpha)\n",
        "                lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
        "                precision = precision_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "                if precision > best_precision:\n",
        "                    best_precision = precision\n",
        "                    best_params = {\n",
        "                        'no_components': no_components,\n",
        "                        'learning_rate': learning_rate,\n",
        "                        'item_alpha': item_alpha,\n",
        "                        'user_alpha': user_alpha\n",
        "                    }\n",
        "\n",
        "print(\"\\nMejores hiperparámetros para LightFM:\")\n",
        "print(best_params)\n",
        "print(f\"Mejor precisión: {best_precision}\")\n",
        "\n",
        "# Entrenar el mejor modelo LightFM\n",
        "lightfm_model = LightFM(loss='warp', **best_params)\n",
        "lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
        "\n",
        "# Re-evaluar el mejor modelo LightFM\n",
        "precision = precision_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "recall = recall_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "print(\"\\nRe-evaluación del modelo LightFM con mejores hiperparámetros:\")\n",
        "print(f\"Precision at {rec}: {precision}\")\n",
        "print(f\"Recall at {rec}: {recall}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cz8E57ivNe5V",
        "outputId": "c3a5e563-b2f3-44a9-821a-529e98ff6003"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top recomendaciones para el usuario usando SVD: 1\n",
            "1. Mother Night (ID: 893)\n",
            "2. A Passage to India (ID: 7087)\n",
            "3. Diabolique (ID: 7116)\n",
            "4. Gladiator 1992 (ID: 8132)\n",
            "5. Cinema Paradiso (ID: 1172)\n",
            "\n",
            "Top recomendaciones para el usuario usando LightFM: 1\n",
            "1. Time Bandits (ID: 2968)\n",
            "2. Dracula (ID: 1339)\n",
            "3. Mad Max 2: The Road Warrior (ID: 3703)\n",
            "4. Gandhi (ID: 1293)\n",
            "5. The Deer Hunter (ID: 1263)\n",
            "\n",
            "\n",
            "\n",
            "Evaluación del modelo SVD:\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8781  0.8742  0.8708  0.8744  0.8680  0.8731  0.0034  \n",
            "MAE (testset)     0.6735  0.6728  0.6693  0.6718  0.6676  0.6710  0.0022  \n",
            "Fit time          5.70    4.79    5.53    4.84    4.88    5.15    0.39    \n",
            "Test time         0.12    0.12    0.18    0.13    0.19    0.15    0.03    \n",
            "\n",
            "Evaluación del modelo LightFM:\n",
            "Precision at 5: 0.8602086901664734\n",
            "Recall at 5: 0.07120333077043094\n",
            "\n",
            "Mejores hiperparámetros para LightFM:\n",
            "{'no_components': 150, 'learning_rate': 0.1, 'item_alpha': 1e-06, 'user_alpha': 1e-06}\n",
            "Mejor precisión: 0.9603577256202698\n",
            "\n",
            "Re-evaluación del modelo LightFM con mejores hiperparámetros:\n",
            "Precision at 5: 0.9564829468727112\n",
            "Recall at 5: 0.08445751440561589\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Entrega 4**\n"
      ],
      "metadata": {
        "id": "lmbotUlbQKUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise\n",
        "!pip install lightfm\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader, SVD\n",
        "from surprise.model_selection import cross_validate, GridSearchCV\n",
        "from lightfm import LightFM\n",
        "from lightfm.evaluation import precision_at_k, recall_at_k\n",
        "from scipy.sparse import coo_matrix\n",
        "import numpy as np\n",
        "\n",
        "# URL del archivo CSV\n",
        "data_url = \"https://raw.githubusercontent.com/JossueGG/tec_bigdata_equipo17/main/ratings_small_entrega2.csv\"\n",
        "\n",
        "# Cargar los datos desde la URL\n",
        "df = pd.read_csv(data_url)\n",
        "\n",
        "# Rango de las calificaciones\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Número de recomendaciones a desplegar\n",
        "rec = 5\n",
        "\n",
        "# Crear un Dataset de Surprise\n",
        "data = Dataset.load_from_df(df[['userId', 'movieId', 'rating']], reader)\n",
        "\n",
        "# Entrenando el modelo SVD\n",
        "trainset = data.build_full_trainset()\n",
        "model = SVD()\n",
        "model.fit(trainset)\n",
        "\n",
        "# Obtener el nombre de la película a partir de su ID\n",
        "movie_titles = df[['movieId', 'title']].drop_duplicates().set_index('movieId')['title'].to_dict()\n",
        "\n",
        "# Función para obtener las mejores recomendaciones para un usuario dado utilizando SVD\n",
        "def get_top_recommendations_svd(user_id, n=rec):\n",
        "    items = []\n",
        "    items_not_rated_by_user = [item for item in range(1, trainset.n_items + 1) if item not in trainset.ur[user_id]]\n",
        "    for item_id in items_not_rated_by_user:\n",
        "        predicted_rating = model.predict(user_id, item_id).est\n",
        "        items.append((item_id, predicted_rating))\n",
        "    top_items = sorted(items, key=lambda x: x[1], reverse=True)[:n]\n",
        "    return [(item[0], movie_titles.get(item[0], \"Título no disponible\")) for item in top_items]\n",
        "\n",
        "# Búsqueda de hiperparámetros para SVD\n",
        "param_grid = {\n",
        "    'n_factors': [20, 50, 100, 150],\n",
        "    'n_epochs': [10, 20, 30, 40, 50],\n",
        "    'lr_all': [0.002, 0.005, 0.01, 0.02],\n",
        "    'reg_all': [0.02, 0.05, 0.1]\n",
        "}\n",
        "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)\n",
        "gs.fit(data)\n",
        "\n",
        "# Mejor modelo SVD\n",
        "best_model = gs.best_estimator['rmse']\n",
        "best_model.fit(data.build_full_trainset())\n",
        "\n",
        "# Crear una matriz de interacciones para LightFM\n",
        "user_ids = df['userId'].astype('category').cat.codes\n",
        "item_ids = df['movieId'].astype('category').cat.codes\n",
        "interactions = coo_matrix((df['rating'], (user_ids, item_ids)))\n",
        "\n",
        "# Ajustar hiperparámetros para LightFM\n",
        "lightfm_model = LightFM(loss='warp', no_components=150, learning_rate=0.05, item_alpha=1e-6, user_alpha=1e-6)\n",
        "lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
        "\n",
        "# Función para obtener las mejores recomendaciones para un usuario dado utilizando LightFM\n",
        "def get_top_recommendations_lightfm(user_id, n=rec):\n",
        "    user_code = df['userId'].astype('category').cat.categories.get_loc(user_id)\n",
        "    scores = lightfm_model.predict(user_code, np.arange(len(movie_titles)))\n",
        "    top_items = np.argsort(-scores)[:n]\n",
        "    return [(df['movieId'].astype('category').cat.categories[item], movie_titles.get(df['movieId'].astype('category').cat.categories[item], \"Título no disponible\")) for item in top_items]\n",
        "\n",
        "# Ejemplo de uso, recomendación para el usuario dado\n",
        "user_id = 1\n",
        "top_recommendations_svd = get_top_recommendations_svd(user_id)\n",
        "top_recommendations_lightfm = get_top_recommendations_lightfm(user_id)\n",
        "\n",
        "print(\"Top recomendaciones para el usuario usando SVD:\", user_id)\n",
        "for rank, (movie_id, title) in enumerate(top_recommendations_svd, 1):\n",
        "    print(f\"{rank}. {title} (ID: {movie_id})\")\n",
        "\n",
        "print(\"\\nTop recomendaciones para el usuario usando LightFM:\", user_id)\n",
        "for rank, (movie_id, title) in enumerate(top_recommendations_lightfm, 1):\n",
        "    print(f\"{rank}. {title} (ID: {movie_id})\")\n",
        "\n",
        "# Evaluar el modelo SVD con 5-fold cross-validation\n",
        "print(\"\\n\\n\\nEvaluación del modelo SVD:\")\n",
        "results_svd = cross_validate(best_model, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)\n",
        "\n",
        "# Evaluar el modelo LightFM\n",
        "precision = precision_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "recall = recall_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "print(\"\\nEvaluación del modelo LightFM:\")\n",
        "print(f\"Precision at {rec}: {precision}\")\n",
        "print(f\"Recall at {rec}: {recall}\")\n",
        "\n",
        "# Ajuste de hiperparámetros LightFM\n",
        "param_grid_lightfm = {\n",
        "    'no_components': [20, 50, 100, 150],\n",
        "    'learning_rate': [0.01, 0.05, 0.1],\n",
        "    'item_alpha': [1e-6, 1e-5, 1e-4],\n",
        "    'user_alpha': [1e-6, 1e-5, 1e-4]\n",
        "}\n",
        "\n",
        "# Buscar los mejores hiperparámetros para LightFM\n",
        "best_precision = 0\n",
        "best_params = None\n",
        "for no_components in param_grid_lightfm['no_components']:\n",
        "    for learning_rate in param_grid_lightfm['learning_rate']:\n",
        "        for item_alpha in param_grid_lightfm['item_alpha']:\n",
        "            for user_alpha in param_grid_lightfm['user_alpha']:\n",
        "                lightfm_model = LightFM(loss='warp', no_components=no_components, learning_rate=learning_rate, item_alpha=item_alpha, user_alpha=user_alpha)\n",
        "                lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
        "                precision = precision_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "                if precision > best_precision:\n",
        "                    best_precision = precision\n",
        "                    best_params = {\n",
        "                        'no_components': no_components,\n",
        "                        'learning_rate': learning_rate,\n",
        "                        'item_alpha': item_alpha,\n",
        "                        'user_alpha': user_alpha\n",
        "                    }\n",
        "\n",
        "print(\"\\nMejores hiperparámetros para LightFM:\")\n",
        "print(best_params)\n",
        "print(f\"Mejor precisión: {best_precision}\")\n",
        "\n",
        "# Entrenar el mejor modelo LightFM\n",
        "lightfm_model = LightFM(loss='warp', **best_params)\n",
        "lightfm_model.fit(interactions, epochs=30, num_threads=2)\n",
        "\n",
        "# Re-evaluar el mejor modelo LightFM\n",
        "precision = precision_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "recall = recall_at_k(lightfm_model, interactions, k=rec).mean()\n",
        "print(\"\\nRe-evaluación del modelo LightFM con mejores hiperparámetros:\")\n",
        "print(f\"Precision at {rec}: {precision}\")\n",
        "print(f\"Recall at {rec}: {recall}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FCND-GAtOV4N",
        "outputId": "b9b07019-cb45-429c-92bd-6be5ded3dfff"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-surprise\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.4.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-surprise) (1.11.4)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp310-cp310-linux_x86_64.whl size=2357253 sha256=eb83b1bbb87b9a0c66d5ab6884c78bf71847a807362472e47a8298d1e30880b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/3f/df/6acbf0a40397d9bf3ff97f582cc22fb9ce66adde75bc71fd54\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise\n",
            "Successfully installed scikit-surprise-1.1.4\n",
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.25.2)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.11.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.31.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2024.6.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.5.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=808333 sha256=b0a5193c39d5ae7d933755672198b485bea4245861cd22dc8d601a4b0fe628b0\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n",
            "Top recomendaciones para el usuario usando SVD: 1\n",
            "1. The Usual Suspects (ID: 50)\n",
            "2. Pulp Fiction (ID: 296)\n",
            "3. The Godfather (ID: 858)\n",
            "4. The Shawshank Redemption (ID: 318)\n",
            "5. Sunset Boulevard (ID: 922)\n",
            "\n",
            "Top recomendaciones para el usuario usando LightFM: 1\n",
            "1. Time Bandits (ID: 2968)\n",
            "2. Ben-Hur (ID: 1287)\n",
            "3. Escape from New York (ID: 1129)\n",
            "4. Star Trek: The Motion Picture (ID: 1371)\n",
            "5. Dracula (ID: 1339)\n",
            "\n",
            "\n",
            "\n",
            "Evaluación del modelo SVD:\n",
            "Evaluating RMSE, MAE of algorithm SVD on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.8760  0.8728  0.8659  0.8746  0.8766  0.8732  0.0039  \n",
            "MAE (testset)     0.6740  0.6740  0.6655  0.6707  0.6722  0.6713  0.0031  \n",
            "Fit time          5.75    4.86    4.99    5.51    4.87    5.20    0.36    \n",
            "Test time         0.36    0.13    0.35    0.13    0.12    0.22    0.11    \n",
            "\n",
            "Evaluación del modelo LightFM:\n",
            "Precision at 5: 0.8572280406951904\n",
            "Recall at 5: 0.07063405518230269\n",
            "\n",
            "Mejores hiperparámetros para LightFM:\n",
            "{'no_components': 150, 'learning_rate': 0.1, 'item_alpha': 0.0001, 'user_alpha': 1e-05}\n",
            "Mejor precisión: 0.965126633644104\n",
            "\n",
            "Re-evaluación del modelo LightFM con mejores hiperparámetros:\n",
            "Precision at 5: 0.9549925923347473\n",
            "Recall at 5: 0.08465382207634131\n"
          ]
        }
      ]
    }
  ]
}